{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d594f613",
   "metadata": {},
   "source": [
    "# Phase 2-3: 小規模な知識グラフを作ってみる【LLM】\n",
    "\n",
    "LLMで文章からトリプルを抽出して知識グラフを作ってみる。\n",
    "\n",
    "## 目標\n",
    "\n",
    "- LLMを使ったトリプル抽出を試してみる\n",
    "- NLPでのトリプル抽出との違いをまとめる\n",
    "\n",
    "## 参考\n",
    "\n",
    "- [LangChain Docs](https://docs.langchain.com/oss/python/langchain/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f9798",
   "metadata": {},
   "source": [
    "## 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c678665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from typing import List, cast\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df79b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e7618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Model : gpt-5-nano-2025-08-07\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_MODEL = str(os.getenv(\"OPENAI_MODEL\"))\n",
    "if OPENAI_MODEL is None:\n",
    "    raise ValueError(\"環境変数 OPENAI_MODEL が設定されていません。\")\n",
    "else:\n",
    "    print(f\"OpenAI Model : {OPENAI_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf8cba",
   "metadata": {},
   "source": [
    "### サンプルテキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Logistic Regression is a model widely used for binary classification.\",\n",
    "    \"Random Forest is an ensemble model of many decision trees.\",\n",
    "    \"Transformer is a model based on the attention mechanism.\",\n",
    "    \"GPT is a Transformer-based model that uses only the decoder block.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cef535",
   "metadata": {},
   "source": [
    "### トリプル抽出処理\n",
    "\n",
    "`with_structured_output` を利用する。そのため、Pydanticでモデルを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914e0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triple(BaseModel):\n",
    "    subject: str = Field(description=\"The subject (noun phrase)\")\n",
    "    verb: str = Field(description=\"The predicate verb in lemma form\")\n",
    "    object: str = Field(description=\"The object (noun phrase)\")\n",
    "\n",
    "class TripleList(BaseModel):\n",
    "    triples: List[Triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca350f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=OPENAI_MODEL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(\n",
    "    schema=TripleList,\n",
    "    method=\"json_schema\",\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \n",
    "        \"\"\"\n",
    "You extract factual SVO triples and return them ONLY in structured JSON.\n",
    "\n",
    "Normalization rules:\n",
    "1. Subjects, verbs, and objects must be normalized to lemma form.\n",
    "2. Multi-word expressions must be converted to snake_case.\n",
    "   - Example: \"binary classification\" → \"binary_classification\"\n",
    "   - Example: \"Logistic Regression\" → \"logistic_regression\"\n",
    "3. Predicates must be verbs in lemma form only.\n",
    "4. Articles and determiners (\"a\", \"the\") must be removed.\n",
    "5. Do NOT include adjectives unless they are semantically necessary.\n",
    "6. Output must strictly follow the provided JSON schema.\n",
    "7. Do NOT output any text outside JSON.\n",
    "\n",
    "Extraction rules:\n",
    "- Extract simple factual SVO relations (subject–verb–object).\n",
    "- If the verb includes a preposition (“used for”), convert it into a single snake_case predicate (“use_for”).\n",
    "- Avoid inventing facts. Only extract what is explicitly stated.\n",
    "\n",
    "Example input:\n",
    "\"Logistic Regression is a model widely used for binary classification.\"\n",
    "\n",
    "Expected normalized triples:\n",
    "[\n",
    "  {{\"subject\": \"logistic_regression\", \"verb\": \"be\", \"object\": \"model\"}},\n",
    "  {{\"subject\": \"logistic_regression\", \"verb\": \"use_for\", \"object\": \"binary_classification\"}}\n",
    "]\n",
    "    \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7687f6",
   "metadata": {},
   "source": [
    "### サンプルテキストでトリプル抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cast(TripleList, chain.invoke({\"text\": texts[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d55d07b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:logistic_regression, V:be, O:model\n",
      "S:logistic_regression, V:use_for, O:binary_classification\n"
     ]
    }
   ],
   "source": [
    "for t in res.triples:\n",
    "    print(f\"S:{t.subject}, V:{t.verb}, O:{t.object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccb4097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripleList(triples=[Triple(subject='logistic_regression', verb='be', object='model'), Triple(subject='logistic_regression', verb='use_for', object='binary_classification')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12b305",
   "metadata": {},
   "source": [
    "### 全てのサンプルテキストで抽出してみよう\n",
    "\n",
    "パイプを使ってパイプライン化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64a5243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is a model widely used for binary classification.\n",
      "Random Forest is an ensemble model of many decision trees.\n",
      "Transformer is a model based on the attention mechanism.\n",
      "GPT is a Transformer-based model that uses only the decoder block.\n"
     ]
    }
   ],
   "source": [
    "def triple_converter(res: TripleList):\n",
    "    return [\n",
    "        {\"subject\": t.subject, \"verb\": t.verb, \"object\": t.object}\n",
    "        for t in res.triples\n",
    "    ]\n",
    "\n",
    "pipeline = chain | triple_converter\n",
    "\n",
    "triples = []\n",
    "for text in texts:\n",
    "    print(text)\n",
    "    triples.extend(pipeline.invoke({\"text\": text}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "021e3bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subject': 'logistic_regression', 'verb': 'be', 'object': 'model'},\n",
       " {'subject': 'logistic_regression',\n",
       "  'verb': 'use_for',\n",
       "  'object': 'binary_classification'},\n",
       " {'subject': 'random_forest', 'verb': 'be', 'object': 'ensemble_model'},\n",
       " {'subject': 'transformer', 'verb': 'be', 'object': 'model'},\n",
       " {'subject': 'model', 'verb': 'base_on', 'object': 'attention_mechanism'},\n",
       " {'subject': 'gpt', 'verb': 'be', 'object': 'transformer_based_model'},\n",
       " {'subject': 'gpt', 'verb': 'use', 'object': 'decoder_block'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"../data/phase_2_outputs/triples_llm.json\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(triples, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a22d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "try-graph-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
