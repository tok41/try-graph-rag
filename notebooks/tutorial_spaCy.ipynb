{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ac5376",
   "metadata": {},
   "source": [
    "# spaCy を触ってみる\n",
    "\n",
    "## spaCyとは\n",
    "\n",
    "品詞推定（POS tagging）、係り受け解析（Dependency Parsing）、固有表現抽出（NER）などを高速に実行できるNLP ライブラリ\n",
    "\n",
    "[document](https://spacy.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f277bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde50d8",
   "metadata": {},
   "source": [
    "## モデルのロード\n",
    "\n",
    "NLPモデルをロードする。英語が精度が良いらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14bf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")  # モデルのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347c861",
   "metadata": {},
   "source": [
    "## サンプルテキスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0734949",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Logistic Regression is a model widely used for binary classification.\",\n",
    "    \"Random Forest is an ensemble model of many decision trees.\",\n",
    "    \"Transformer is a model based on the attention mechanism.\",\n",
    "    \"GPT is a Transformer-based model that uses only the decoder block.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006551af",
   "metadata": {},
   "source": [
    "## 品詞のタグづけ\n",
    "\n",
    "各単語の品詞の推定と係り受け関係を推定する\n",
    "\n",
    "[attributes](https://spacy.io/api/token#attributes)\n",
    "\n",
    "- lemma: tokenの基本形\n",
    "- POS: 荒い粒度の品詞（[POS tags](https://universaldependencies.org/u/pos/)）\n",
    "- tag: 品詞\n",
    "- dep: 依存関係（係り受けのラベル）\n",
    "- shape: トークン文字列の変換（アルファベット文字は x or X, 数字は d, 同じ文字の連続は長さ4文字以降切り捨て）\n",
    "- is_alpha: アルファベット文字列で構成されているか\n",
    "- is_stop: 停止文字列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f6034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text | lemma | POS(荒い品詞) | tag(細かい品詞) | dep(係り受けラベル) | shape | is_alpha | is_stop\n",
      "Logistic | Logistic | PROPN | NNP | compound | Xxxxx | True | False\n",
      "Regression | Regression | PROPN | NNP | nsubj | Xxxxx | True | False\n",
      "is | be | AUX | VBZ | ROOT | xx | True | True\n",
      "a | a | DET | DT | det | x | True | True\n",
      "model | model | NOUN | NN | attr | xxxx | True | False\n",
      "widely | widely | ADV | RB | advmod | xxxx | True | False\n",
      "used | use | VERB | VBN | acl | xxxx | True | True\n",
      "for | for | ADP | IN | prep | xxx | True | True\n",
      "binary | binary | ADJ | JJ | amod | xxxx | True | False\n",
      "classification | classification | NOUN | NN | pobj | xxxx | True | False\n",
      ". | . | PUNCT | . | punct | . | False | False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "\n",
    "print(\"text | lemma | POS(荒い品詞) | tag(細かい品詞) | dep(係り受けラベル) | shape | is_alpha | is_stop\")\n",
    "for token in doc:\n",
    "    print(\n",
    "        f\"{token.text} | {token.lemma_} | {token.pos_} | {token.tag_} | {token.dep_} | {token.shape_} | {token.is_alpha} | {token.is_stop}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a732e13",
   "metadata": {},
   "source": [
    "## 名詞句の抽出(標準機能)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "034a6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is a model widely used for binary classification.\n",
      "Logistic Regression\n",
      "a model\n",
      "binary classification\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "print(doc.text)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7588d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest is an ensemble model of many decision trees.\n",
      "Random Forest\n",
      "an ensemble model\n",
      "many decision trees\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[1])\n",
    "print(doc.text)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81962ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer is a model based on the attention mechanism.\n",
      "Transformer\n",
      "a model\n",
      "the attention mechanism\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[2])\n",
    "print(doc.text)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b1a3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2065a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT is a Transformer-based model that uses only the decoder block.\n",
      "GPT\n",
      "a Transformer-based model\n",
      "that\n",
      "only the decoder block\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[3])\n",
    "print(doc.text)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4fad3",
   "metadata": {},
   "source": [
    "## 名詞句の抽出（カスタム）\n",
    "\n",
    "シンプルな名詞句を抽出したいので、カスタムのヘルパー関数を作る。\n",
    "a とか the とかいらないとか。\n",
    "\n",
    "- dep(係り受けラベル)が `commpound` は後ろの語の修飾語なのでくっつける\n",
    "    - nsubj: 主語\n",
    "    - nsubjpass: 受動態の主語\n",
    "    - dobj: 直接目的語\n",
    "    - pobj: 前置詞の目的語\n",
    "    - attr: be動詞の補語\n",
    "    - compound: 名詞の前からの就職（名詞句を一つにまとめる）\n",
    "    - amod: 名詞を修飾する形容詞\n",
    "- 限定詞は除外\n",
    "- `token.lefts` は、依存関係のある左側の単語\n",
    "    - 修飾する語を表す\n",
    "\n",
    "整理したロジック\n",
    "\n",
    "1.\t文中の各 token について：\n",
    "    - token.dep_ が {\"nsubj\", \"nsubjpass\", \"dobj\", \"pobj\", \"attr\"} のとき\n",
    "    - かつ token.pos_ in {\"NOUN\", \"PROPN\"} なら「名詞句ヘッド」とみなす\n",
    "2.\tそのヘッド token について token.lefts から：\n",
    "    - dep_ が {\"compound\", \"amod\"} の子をすべて集める\n",
    "3.\tそれらをヘッド token と合わせて .i（位置）順に並べて join\n",
    "    - → \"Logistic Regression\", \"binary classification\" みたいな名詞句になる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cae5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_chunks(doc):\n",
    "    HEAD_DEPS = {\"nsubj\", \"nsubjpass\", \"dobj\", \"pobj\", \"attr\"}\n",
    "    NOUN_POS = {\"NOUN\", \"PROPN\"}\n",
    "    MODIFIER_DEPS = {\"compound\", \"amod\"}\n",
    "\n",
    "    chunks = {}\n",
    "    for token in doc:\n",
    "        if (token.dep_ in HEAD_DEPS) and (token.pos_ in NOUN_POS):\n",
    "            modifiers = [child for child in token.lefts if child.dep_ in MODIFIER_DEPS]\n",
    "            noun_parts = sorted(modifiers + [token], key=lambda t: t.i)\n",
    "            phrase = \" \".join(tok.lemma_ for tok in noun_parts)\n",
    "            chunks[token] = phrase\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d54f1967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Regression: 'Logistic Regression',\n",
       " model: 'model',\n",
       " classification: 'binary classification'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "get_noun_chunks(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b0e58",
   "metadata": {},
   "source": [
    "## SVOを抽出（1文）\n",
    "\n",
    "トリプル構造を抽出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590aa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from src.spacy_helper import get_noun_phrase_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeca946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target sentence: Logistic Regression is a model widely used for binary classification.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "print(f\"target sentence: {doc.text}\")\n",
    "\n",
    "noun_map = get_noun_phrase_map(doc=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "578bf4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb : is, be\n",
      "[Regression]\n",
      "[model]\n",
      "{'subject': 'Logistic Regression', 'verb': 'be', 'object': 'model'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VERB_POS = {\"VERB\", \"AUX\"}\n",
    "VERB_DEP = {\"ROOT\", \"conj\"}\n",
    "\n",
    "svos = []\n",
    "for token in doc:\n",
    "    # まずは動詞を見つける\n",
    "    if (token.dep_ in VERB_DEP) and (token.pos_ in VERB_POS):\n",
    "        print(f\"verb : {token.text}, {token.lemma_}\")\n",
    "        # 主語(S)候補と目的語(O)候補を抽出\n",
    "        subjects = [child for child in token.children if child.dep_ in {\"nsubj\", \"nsubjpass\"}]\n",
    "        objects = [child for child in token.children if child.dep_ in {\"dobj\", \"attr\"}]\n",
    "        print(subjects)\n",
    "        print(objects)\n",
    "        # 名詞句mapでフレーズを抽出\n",
    "        subject_phrase = [noun_map.get(tok, tok.lemma_) for tok in subjects]\n",
    "        object_phrase = [noun_map.get(tok, tok.lemma_) for tok in objects]\n",
    "        # SとOの組み合わせで SVO を抽出\n",
    "        trps = [{\"subject\": s, \"verb\":token.lemma_, \"object\": o} for s, o in itertools.product(subject_phrase, object_phrase)]\n",
    "        svos.extend(trps)\n",
    "\n",
    "for svo in svos:\n",
    "    print(svo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8adf1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spacy_helper import get_svo_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621d857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subject': 'Logistic Regression', 'verb': 'be', 'object': 'model'},\n",
       " {'subject': 'model', 'verb': 'use_for', 'object': 'binary classification'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svos = get_svo_from_sentence(doc, noun_map)\n",
    "svos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f72c69",
   "metadata": {},
   "source": [
    "## SVO抽出（前置詞拡張）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ad89a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target sentence: Logistic Regression is a model widely used for binary classification.\n",
      "verb : is, be\n",
      "subjects:  [Regression]\n",
      "objects:  [model]\n",
      "preps:  []\n",
      "verb : used, use\n",
      "subjects:  [model]\n",
      "objects:  []\n",
      "preps:  [for]\n",
      "{'subject': 'Logistic Regression', 'verb': 'be', 'object': 'model'}\n",
      "\n",
      "{'subject': 'model', 'verb': 'use_for', 'object': 'binary classification'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# doc = nlp(\"The model is used for binary classification.\")\n",
    "doc = nlp(texts[0])\n",
    "noun_map = get_noun_phrase_map(doc=doc)\n",
    "print(f\"target sentence: {doc.text}\")\n",
    "\n",
    "NOUN_POS = {\"NOUN\", \"PROPN\"}\n",
    "VERB_POS = {\"VERB\", \"AUX\"}\n",
    "VERB_DEP = {\"ROOT\", \"conj\", \"acl\"}\n",
    "\n",
    "svos = []\n",
    "for token in doc:\n",
    "    # まずは動詞を見つける\n",
    "    if (token.dep_ in VERB_DEP) and (token.pos_ in VERB_POS):\n",
    "        print(f\"verb : {token.text}, {token.lemma_}\")\n",
    "        # 主語(S)候補と目的語(O)候補を抽出\n",
    "        subjects = [child for child in token.children if child.dep_ in {\"nsubj\", \"nsubjpass\"}]\n",
    "        if not subjects and token.dep_ == \"acl\":  # acl 動詞の場合は head 名詞を主語候補にする\n",
    "            head = token.head\n",
    "            if head.pos_ in NOUN_POS:\n",
    "                subjects = [head]\n",
    "        objects = [child for child in token.children if child.dep_ in {\"dobj\", \"attr\"}]\n",
    "        preps = [child for child in token.children if child.dep_ == \"prep\"]\n",
    "        print(\"subjects: \", subjects)\n",
    "        print(\"objects: \", objects)\n",
    "        print(\"preps: \", preps)\n",
    "        # 名詞句mapでフレーズを抽出\n",
    "        subject_phrase = [noun_map.get(tok, tok.lemma_) for tok in subjects]\n",
    "        object_phrase = [noun_map.get(tok, tok.lemma_) for tok in objects]\n",
    "        pobj_candidates = []\n",
    "        for prep in preps:\n",
    "            pobj_candidates = [c for c in prep.children if c.dep_ == \"pobj\"]\n",
    "        pp_objects = [noun_map.get(tok, tok.lemma_) for tok in pobj_candidates]\n",
    "        # SとOの組み合わせで SVO を抽出\n",
    "        trps = [{\"subject\": s, \"verb\":token.lemma_, \"object\": o} for s, o in itertools.product(subject_phrase, object_phrase)]\n",
    "        svos.extend(trps)\n",
    "        # 前置詞のトリプル抽出\n",
    "        for prep in preps:\n",
    "            verb_prep = f\"{token.lemma_}_{prep.text}\"\n",
    "            pobj_tokens = [c for c in prep.children if c.dep_ == \"pobj\"]\n",
    "            pp_objects = [noun_map.get(tok, tok.lemma_) for tok in pobj_tokens]\n",
    "            for s in subject_phrase:\n",
    "                for o in pp_objects:\n",
    "                    svos.append({\"subject\": s, \"verb\": verb_prep, \"object\": o})\n",
    "\n",
    "for svo in svos:\n",
    "    print(svo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3697a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spacy_helper import get_svo_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d952bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target sentence: The model is used for binary classification.\n",
      "{'subject': 'model', 'verb': 'use_for', 'object': 'binary classification'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 関数化した\n",
    "doc = nlp(\"The model is used for binary classification.\")\n",
    "print(f\"target sentence: {doc.text}\")\n",
    "noun_map = get_noun_phrase_map(doc=doc)\n",
    "\n",
    "svos = get_svo_from_sentence(doc, noun_map)\n",
    "\n",
    "for svo in svos:\n",
    "    print(svo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bf356a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target sentence: Logistic Regression is a model widely used for binary classification.\n",
      "{'subject': 'Logistic Regression', 'verb': 'be', 'object': 'model'}\n",
      "\n",
      "{'subject': 'model', 'verb': 'use_for', 'object': 'binary classification'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "print(f\"target sentence: {doc.text}\")\n",
    "noun_map = get_noun_phrase_map(doc=doc)\n",
    "\n",
    "svos = get_svo_from_sentence(doc, noun_map)\n",
    "\n",
    "for svo in svos:\n",
    "    print(svo)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f0025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "try-graph-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
